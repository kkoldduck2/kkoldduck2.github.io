---
layout: single
title:  "[íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œ] 2ì¥-ì‚¬ì´í‚·ëŸ°ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹-1"
categories: ML
tag: [ML, íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œ, ë¨¸ì‹ ëŸ¬ë‹, ë„˜íŒŒì´, íŒë‹¤ìŠ¤]
toc: true
author_profile: true
---
# 1. ì‚¬ì´í‚·ëŸ°ì„ ì´ìš©í•˜ì—¬ ë¶“ê½ƒ(Iris) ë°ì´í„° í’ˆì¢… ì˜ˆì¸¡í•˜ê¸°

<aside>
ğŸ“– - ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¡œ ë¶“ê½ƒì˜ í’ˆì¢…ì„ **ë¶„ë¥˜(Classification)**í•´ë³´ì

- ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ëŠ” ê½ƒìì˜ ê¸¸ì´ì™€ ë„ˆë¹„, ê½ƒë°›ì¹¨ì˜ ê¸¸ì´ì™€ ë„ˆë¹„ Featureë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê½ƒì˜ í’ˆì¢…ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ê²ƒ

</aside>

- ì‚¬ì´í‚·ëŸ° ëª¨ë“ˆ ì •ë¦¬
    - `sklearn.datasetes` : ì‚¬ì´í‚·ëŸ°ì—ì„œ ìì²´ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë“ˆì˜ ëª¨ì„
    - `sklearn.model_selection` : í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°, ì˜ˆì¸¡ ë°ì´í„°ë¡œ **ë°ì´í„°ë¥¼ ë¶„ë¦¬**í•˜ê±°ë‚˜ **ìµœì ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°**ë¡œ í‰ê°€í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ëª¨ë“ˆì˜ ëª¨ì„
        - í•˜ì´í¼ íŒŒë¼ë¯¸í„°
            - ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë³„ë¡œ ìµœì ì˜ í•™ìŠµì„ ìœ„í•´ ì§ì ‘ ì…ë ¥í•˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ í†µì¹­
            - í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ íŠœë‹í•  ìˆ˜ ìˆë‹¤.

### 1) ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬

- ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„° ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬
- train_test_split

- **ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë”©**

```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
import sklearn
import pandas as pd

# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë”©
iris = load_iris()
```

- **Iris ë°ì´í„° ì„¸íŠ¸ì—ì„œ feature, target ê°’ ê°€ì ¸ì™€ì„œ DataFrame ìƒì„±**

```python
# iris.dataëŠ” Iris ë°ì´í„° ì„¸íŠ¸ì—ì„œ í”¼ì²˜(feature)ë§Œìœ¼ë¡œ ëœ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìŒ (numpy) 
iris_data = iris.data

# iris.targetì€ ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë ˆì´ë¸” ê°’ì„ ê°€ì§€ê³  ìˆìŒ (numpy) 
iris_label = iris.target
print('iris targetê°’:', iris_label) # [0 0 0 ... 1 1 1 ... 2 2 2 ...]
print('iris targetëª…:', iris.target_names)    # ['setosa' 'versicolor' 'virginica']

# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìì„¸íˆ ë³´ê¸° ìœ„í•´ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
iris_df['label'] = iris.target
iris_df.head(3)
```


- **ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬**

```python
from sklearn.model_selection import train_test_split
#1.ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬
#train_test_split(í”¼ì³ë°ì´í„°ì…‹,ë ˆì´ë¸”ë°ì´í„°ì„¸íŠ¸,í…ŒìŠ¤íŠ¸ë°ì´í„° ì„¸íŠ¸ ë¹„ìœ¨, ë‚œìˆ˜ë°œìƒê°’)
**X_train, X_test, y_train, y_test** = **train_test_split**(iris_data, iris_label, 
                                                    test_size=0.2, random_state=11)
```

### 2) ëª¨ë¸ í•™ìŠµ

- í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•´ ëª¨ë¸ì„ í•™ìŠµ
- fit

- **DecisionTreeClassifier ê°ì²´ ìƒì„± ë° ëª¨ë¸ í•™ìŠµ**
    - ML ì•Œê³ ë¦¬ì¦˜ì€ ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬(Decision Tree) ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ DecisionTreeClassifierë¥¼ ì ìš©í•¨

```python
from sklearn.tree import DecisionTreeClassifier

# DecisionTreeClassifier ê°ì²´ ìƒì„± 
dt_clf = DecisionTreeClassifier(random_state=11)

#2. ëª¨ë¸í•™ìŠµ
# í•™ìŠµ ìˆ˜í–‰ 
dt_clf.fit(X_train, y_train)
```

### 3) ì˜ˆì¸¡ ìˆ˜í–‰

- í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¶„ë¥˜ë¥¼ ì˜ˆì¸¡
- predict

```python
#3. ì˜ˆì¸¡ìˆ˜í–‰
# í•™ìŠµì´ ì™„ë£Œëœ DecisionTreeClassifier ê°ì²´ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰. 
**pred** = dt_clf.predict(X_test)
```

### 4) í‰ê°€

- ì˜ˆì¸¡ëœ ê²°ê³¼ê°’ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì‹¤ì œ ê²°ê³¼ê°’ì„ ë¹„êµ â†’ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

```python
#4. í‰ê°€
from sklearn.metrics import accuracy_score
print('ì˜ˆì¸¡ ì •í™•ë„: {0:.4f}'.format(**accuracy_score**(y_test,**pred**))) # 0.9333
```

# 2. êµì°¨ ê²€ì¦

- **ê³¼ì í•©(Overfitting)**
    - ê³ ì •ëœ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€ë¥¼ í•˜ë‹¤ë³´ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ë§Œ ìµœì ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡ í¸í–¥ë˜ê²Œ ëª¨ë¸ì„ ìœ ë„í•˜ëŠ” ê²½í–¥ì´ ìƒê¸´ë‹¤.
    - ê²°êµ­ í•´ë‹¹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ë§Œ ê³¼ì í•©ë˜ëŠ” í•™ìŠµ ëª¨ë¸ì´ ë§Œë“¤ì–´ì ¸ ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš°ì—ëŠ” ì„±ëŠ¥ì´ ì €í•˜ë˜ê²Œ ëœë‹¤.
    - ì´ëŸ¬í•œ ë¬¸ì œì ì„ ê°œì„ í•˜ê¸° ìœ„í•´ êµì°¨ ê²€ì¦ì„ ì´ìš©í•´ ë‹¤ì–‘í•œ í•™ìŠµê³¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•œë‹¤.


### 1) K í´ë“œ êµì°¨ê²€ì¦

- Kê°œì˜ ë°ì´í„° í´ë“œ ì„¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ Kë²ˆë§Œí¼ ê° í´ë“œ ì„¸íŠ¸ì— í•™ìŠµ, ê²€ì¦, í‰ê°€ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•


```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
import numpy as np

iris = load_iris()
features = iris.data
label = iris.target
dt_clf = DecisionTreeClassifier(random_state=156)

# 5ê°œì˜ í´ë“œ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•˜ëŠ” KFold ê°ì²´ì™€ í´ë“œ ì„¸íŠ¸ë³„ ì •í™•ë„ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ê°ì²´ ìƒì„±.
kfold = KFold(n_splits=5)       # shuffle ë””í´íŠ¸ ì˜µì…˜ì´ false -> ìˆœì°¨ì ìœ¼ë¡œ ë¶„ë¦¬ë¨. 
cv_accuracy = []
print('ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ í¬ê¸°:',features.shape[0])   # 150  
```

```python
n_iter = 0

# 120ê°œ, 30ê°œë¡œ ë‚˜ëˆ ì„œ 120ê°œë¡œ í•™ìŠµ, 30ê°œë¡œ í…ŒìŠ¤íŠ¸ -> ì´ê±¸ 5ë²ˆ ë°˜ë³µí•œë‹¤.
# KFoldê°ì²´ì˜ split( ) í˜¸ì¶œí•˜ë©´ í´ë“œ ë³„ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ì˜ ë¡œìš° ì¸ë±ìŠ¤ë¥¼ arrayë¡œ ë°˜í™˜  
for train_index, test_index  in **kfold.split(features)**:
    # kfold.split( )ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
    ## train_index : numpy (fancy indexing) -> ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ê°’ë“¤ì„ ë¦¬í„´
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]

    #í•™ìŠµ ë° ì˜ˆì¸¡ 
    dt_clf.fit(X_train , y_train)    
    pred = dt_clf.predict(X_test)
    n_iter += 1

    # ë°˜ë³µ ì‹œ ë§ˆë‹¤ ì •í™•ë„ ì¸¡ì • 
    accuracy = np.round(accuracy_score(y_test,pred), 4)
    train_size = X_train.shape[0]
    test_size = X_test.shape[0]
    print('\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ :{1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {3}'
          .format(n_iter, accuracy, train_size, test_size))
    print('#{0} ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:{1}'.format(n_iter,test_index))
    cv_accuracy.append(accuracy)
    
# ê°œë³„ iterationë³„ ì •í™•ë„ë¥¼ í•©í•˜ì—¬ í‰ê·  ì •í™•ë„ ê³„ì‚° 
print('\n## í‰ê·  ê²€ì¦ ì •í™•ë„:', np.mean(cv_accuracy))
```

- ê²°ê³¼
    
    ```
    #1 êµì°¨ ê²€ì¦ ì •í™•ë„ :1.0, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ê¸°: 30
    #1 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]
    
    #2 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9667, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ê¸°: 30
    #2 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]
    
    #3 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.8667, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ê¸°: 30
    #3 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
    
    #4 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9333, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ê¸°: 30
    #4 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]
    
    #5 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.7333, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ê¸°: 30
    #5 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149]
    
    ## í‰ê·  ê²€ì¦ ì •í™•ë„: 0.9
    ```
    

### 2) Stratified K í´ë“œ

- ë¶ˆê· í˜•í•œ(imbalanced) ë¶„í¬ë„ë¥¼ ê°€ì§„ ë ˆì´ë¸” ë°ì´í„° ì§‘í•©ì„ ìœ„í•œ K í´ë“œ ë°©ì‹
- ë¶ˆê· í˜•í•œ ë¶„í¬ë„ë¥¼ ê°€ì§„ ë ˆì´ë¸” ë°ì´í„° ì§‘í•© :  íŠ¹ì • ë ˆì´ë¸” ê°’ì´ íŠ¹ì´í•˜ê²Œ ë§ê±°ë‚˜ ë§¤ìš° ì ì–´ì„œ ê°’ì˜ ë¶„í¬ê°€ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹˜ëŠ” ê²ƒ.
    - ì˜ˆ : ëŒ€ì¶œ ì‚¬ê¸° ë°ì´í„° ì˜ˆì¸¡ :
        - ëŒ€ì¶œ ì‚¬ê¸° ì—¬ë¶€ë¥¼ ëœ»í•˜ëŠ” ë ˆì´ë¸” (ëŒ€ì¶œ ì‚¬ê¸° :1, ì •ìƒ ëŒ€ì¶œ : 0)
        - ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ëŠ” ì •ìƒ ëŒ€ì¶œ. ë§¤ìš° ì‘ì€ ë¹„ìœ¨ë¡œ 1 ë ˆì´ë¸” ê°’ì´ ì¡´ì¬
        - íŠ¹ì • ë°ì´í„° ì„¸íŠ¸ì—ëŠ” 1ì´ ìƒëŒ€ì ìœ¼ë¡œ ë§ì´ ë“¤ì–´ê°€ ìˆê³ , ë‹¤ë¥¸ ë°˜ë³´ê³  í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ê·¸ë ‡ì§€ ëª»í•œ ê²°ê³¼ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ
        - ë”°ë¼ì„œ ì›ë³¸ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ëŒ€ì¶œ ì‚¬ê¸° ë ˆì´ë¸” ê°’ì˜ ë¶„í¬ë¥¼ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ë„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤.
- Stratified K í´ë“œëŠ” ì´ì²˜ëŸ¼ K í´ë“œê°€ ë ˆì´ë¸” ë°ì´í„° ì§‘í•©ì´ ì›ë³¸ ë°ì´í„° ì§‘í•©ì˜ ë ˆì´ë¸” ë¶„í¬ë¥¼ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì œëŒ€ë¡œ ë¶„ë°°í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ì˜ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.
- **Stratified K í´ë“œëŠ” ì›ë³¸ ë°ì´í„°ì˜ ë ˆì´ë¸” ë¶„í¬ë¥¼ ë¨¼ì € ê³ ë ¤í•œ ë’¤ ì´ ë¶„í¬ì™€ ë™ì¼í•˜ê²Œ í•™ìŠµê³¼ ê²€ì¦ ë°ì´í„°ë¥¼ ë¶„ë°°í•œë‹¤.**

```python
import pandas as pd

iris = load_iris()

iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['label']=iris.target
iris_df['label'].value_counts()
---------------------------------------------
0    50
1    50
2    50
Name: label, dtype: int6
```

- ë ˆì´ë¸” ê°’ì€ 0,1,2 ê°’ ëª¨ë‘ 50ê°œë¡œ ë™ì¼.
- í•˜ì§€ë§Œ ë°ì´í„°ë¥¼ ë³´ë©´ ê°™ì€ í’ˆì¢…ë¼ë¦¬ ì„œë¡œ ëª°ë ¤ìˆìŒ â†’ K=3ì¸ KFoldë¡œ í…ŒìŠ¤íŠ¸í–ˆì„ ë•Œ ë¬¸ì œ ë°œìƒ

```python
kfold = KFold(n_splits=3)
n_iter =0
for train_index, test_index  in kfold.split(iris_df):
    n_iter += 1
    label_train= iris_df['label'].iloc[train_index]
    label_test= iris_df['label'].iloc[test_index]
    print('## êµì°¨ ê²€ì¦: {0}'.format(n_iter))
    print('í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n', label_train.value_counts())
    print('ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n', label_test.value_counts())
```

```python
## êµì°¨ ê²€ì¦: 1
í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 1    50
2    50
Name: label, dtype: int64
ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 0    50
Name: label, dtype: int64
## êµì°¨ ê²€ì¦: 2
í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 0    50
2    50
Name: label, dtype: int64
ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 1    50
Name: label, dtype: int64
## êµì°¨ ê²€ì¦: 3
í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 0    50
1    50
Name: label, dtype: int64
ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 2    50
Name: label, dtype: int64
```

- í•™ìŠµì€ 1,2ë²ˆìœ¼ë¡œë§Œ í•˜ê³ , í…ŒìŠ¤íŠ¸ëŠ” 0ë²ˆìœ¼ë¡œë§Œ í…ŒìŠ¤íŠ¸í•˜ê²Œ ë¨. ì¦‰ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì„œë¡œ ì™„ì „íˆ ë¶„ë¦¬ë˜ì–´ìˆìŒ
    
    â†’ 0ì˜ ê²½ìš°ë¥¼ ì „í˜€ í•™ìŠµí•˜ì§€ ëª»í•¨
    
    â†’ ê²€ì¦ ì—ì¸¡ ì •í™•ë„ëŠ” 0ì´ ë¨
    
- ë”°ë¼ì„œ í•™ìŠµë„ 0,1,2ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ 0,1,2ë¡œ ê³ ë¥´ê²Œ êµ¬ì„±ë˜ì–´ ìˆì–´ì•¼ í•™ìŠµì´ ì œëŒ€ë¡œ ì¼ì–´ë‚œë‹¤.
- â‡’ stratified KFold ì‚¬ìš©

```python
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=3)
n_iter=0

for train_index, test_index in skf.split(iris_df, iris_df['label']):
    n_iter += 1
    label_train= iris_df['label'].iloc[train_index]
    label_test= iris_df['label'].iloc[test_index]
    print('## êµì°¨ ê²€ì¦: {0}'.format(n_iter))
    print('í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n', label_train.value_counts())
    print('ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n', label_test.value_counts())
```

```python
## êµì°¨ ê²€ì¦: 1
í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 2    34
0    33
1    33
Name: label, dtype: int64
ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 0    17
1    17
2    16
Name: label, dtype: int64
## êµì°¨ ê²€ì¦: 2
í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 1    34
0    33
2    33
Name: label, dtype: int64
ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 0    17
2    17
1    16
Name: label, dtype: int64
## êµì°¨ ê²€ì¦: 3
í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 0    34
1    33
2    33
Name: label, dtype: int64
ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:
 1    17
2    17
0    16
Name: label, dtype: int64
```

- ë ˆì´ë¸” ë³„ë¡œ ë™ì¼í•œ ë¹„ìœ¨ë¡œ í• ë‹¹ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```python
dt_clf = DecisionTreeClassifier(random_state=156)

skfold = StratifiedKFold(n_splits=3)
n_iter=0
cv_accuracy=[]

# StratifiedKFoldì˜ split( ) í˜¸ì¶œì‹œ ë°˜ë“œì‹œ ë ˆì´ë¸” ë°ì´í„° ì…‹ë„ ì¶”ê°€ ì…ë ¥ í•„ìš”  
for train_index, test_index  in skfold.split(features, label):
    # split( )ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]
    #í•™ìŠµ ë° ì˜ˆì¸¡ 
    dt_clf.fit(X_train , y_train)    
    pred = dt_clf.predict(X_test)

    # ë°˜ë³µ ì‹œ ë§ˆë‹¤ ì •í™•ë„ ì¸¡ì • 
    n_iter += 1
    accuracy = np.round(accuracy_score(y_test,pred), 4)
    train_size = X_train.shape[0]
    test_size = X_test.shape[0]
    print('\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ :{1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {3}'
          .format(n_iter, accuracy, train_size, test_size))
    print('#{0} ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:{1}'.format(n_iter,test_index))
    cv_accuracy.append(accuracy)
    
# êµì°¨ ê²€ì¦ë³„ ì •í™•ë„ ë° í‰ê·  ì •í™•ë„ ê³„ì‚° 
print('\n## êµì°¨ ê²€ì¦ë³„ ì •í™•ë„:', np.round(cv_accuracy, 4))
print('## í‰ê·  ê²€ì¦ ì •í™•ë„:', np.mean(cv_accuracy))
```

```python
#1 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.98, í•™ìŠµ ë°ì´í„° í¬ê¸°: 100, ê²€ì¦ ë°ì´í„° í¬ê¸°: 50
#1 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50
  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101
 102 103 104 105 106 107 108 109 110 111 112 113 114 115]

#2 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.94, í•™ìŠµ ë°ì´í„° í¬ê¸°: 100, ê²€ì¦ ë°ì´í„° í¬ê¸°: 50
#2 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67
  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118
 119 120 121 122 123 124 125 126 127 128 129 130 131 132]

#3 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.98, í•™ìŠµ ë°ì´í„° í¬ê¸°: 100, ê²€ì¦ ë°ì´í„° í¬ê¸°: 50
#3 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84
  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135
 136 137 138 139 140 141 142 143 144 145 146 147 148 149]

## êµì°¨ ê²€ì¦ë³„ ì •í™•ë„: [0.98 0.94 0.98]
## í‰ê·  ê²€ì¦ ì •í™•ë„: 0.9666666666666667
```

### 3) cross_val_score()

- ìœ„ êµì°¨ ê²€ì¦(í´ë“œ ì„¸íŠ¸ ì„¤ì • â†’ for ë£¨í”„ì—ì„œ ë°˜ë³µìœ¼ë¡œ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ â†’ ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµê³¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì˜ˆì¸¡ ì„±ëŠ¥ ë°˜í™˜) ê³¼ì •ì„ ê°„ë‹¨í•˜ê²Œ í•˜ëŠ” ë°©ë²•
- cross_val_score(**estimator**, **X**, **y**=None, *, groups=None, **scoring**=None, **cv**=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=np.nan)
    - `estimator` : Classifier í˜¹ì€ Regressor
        - classifierê°€ ì…ë ¥ë˜ë©´ Stratified K í´ë“œ ë°©ì‹ìœ¼ë¡œ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ë¶„í• 
        - Regressorì¸ ê²½ìš° Stratified K í´ë“œ ë°©ì‹ìœ¼ë¡œ ë¶„í• í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ K í´ë“œ ë°©ì‹ìœ¼ë¡œ ë¶„í• 
    - `X` : í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸
    - `y` : ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸
    - `scoring` : ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ
    - `cv` : êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score , cross_validate
from sklearn.datasets import load_iris
import numpy as np

iris_data = load_iris()
dt_clf = DecisionTreeClassifier(random_state=156)

data = iris_data.data
label = iris_data.target

#ì„±ëŠ¥ í‰ê°€ ì§€í‘œëŠ” ì •í™•ë„ì¸ accuracyë¡œ í•¨
scores = cross_val_score(dt_clf , data , label , scoring='accuracy',cv=3)  #Straified?
print('êµì°¨ ê²€ì¦ë³„ ì •í™•ë„:',np.round(scores, 4))
print('í‰ê·  ê²€ì¦ ì •í™•ë„:', np.round(np.mean(scores), 4))
```

### 4) GridSearchCV - êµì°¨ ê²€ì¦ê³¼ ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•œë²ˆì—

- í•˜ì´í¼ íŒŒë¼ë¯¸í„°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œì´ë©°, ì´ ê°’ì„ ì¡°ì •í•´ ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆë‹¤.
- ì‚¬ì´í‚·ëŸ°ì€ GridSearchCV APIë¥¼ ì´ìš©í•´ Classifierë‚˜ Regressorì™€ ê°™ì€ ì•Œê³ ë¦¬ì¦˜ì— ì‚¬ìš©ë˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ â†’ í¸ë¦¬í•˜ê²Œ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆëŠ” ë°©ì•ˆ ì œê³µ

```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  í•™ìŠµë°ì´íƒ€ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, 
                                                    test_size=0.2, random_state=121)
dtree = DecisionTreeClassifier()

### hyper parameter ë“¤ì„ dictionary í˜•íƒœë¡œ ì„¤ì •
parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}
```

```python
import pandas as pd

# param_gridì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë“¤ì„ 3ê°œì˜ train, test set fold ë¡œ ë‚˜ëˆ„ì–´ì„œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì„¤ì •.  => **6ê°œì˜ íŒŒë¼ë¯¸í„° ì¡°í•© X CV 3íšŒ -> 18íšŒì˜ í•™ìŠµ/í‰ê°€ê°€ ì´ë¤„ì§„ë‹¤**. 
### refit=True ê°€ default ì„. Trueì´ë©´ ê°€ì¥ ì¢‹ì€ íŒŒë¼ë¯¸í„° ì„¤ì •ìœ¼ë¡œ ì¬ í•™ìŠµ ì‹œí‚´.  
grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)

# ë¶“ê½ƒ Train ë°ì´í„°ë¡œ param_gridì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµ/í‰ê°€ .
grid_dtree.fit(X_train, y_train)

# GridSearchCV ê²°ê³¼ ì¶”ì¶œí•˜ì—¬ DataFrameìœ¼ë¡œ ë³€í™˜
scores_df = pd.DataFrame(grid_dtree.cv_results_)
scores_df[['params', 'mean_test_score', 'rank_test_score', \
           'split0_test_score', 'split1_test_score', 'split2_test_score']]
```


```python
print('GridSearchCV ìµœì  íŒŒë¼ë¯¸í„°:', grid_dtree.best_params_)
# {'max_depth': 3, 'min_samples_split': 2}

print('GridSearchCV ìµœê³  ì •í™•ë„: {0:.4f}'.format(grid_dtree.best_score_))  # 0.9750
```

```python
# GridSearchCVì˜ refitìœ¼ë¡œ ì´ë¯¸ í•™ìŠµì´ ëœ estimator ë°˜í™˜
estimator = grid_dtree.best_estimator_

# GridSearchCVì˜ best_estimator_ëŠ” ì´ë¯¸ ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµì´ ë¨
pred = estimator.predict(X_test)
print('í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ ì •í™•ë„: {0:.4f}'.format(accuracy_score(y_test,pred))) # 0.9667
```

# 3. ë°ì´í„° ì „ì²˜ë¦¬

- ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ë§¤ìš° ì¤‘ìš”í•˜ë‹¤. ì…ë ¥ê°’ì— ë”°ë¼ ê²°ê³¼ê°€ í¬ê²Œ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸
- Null ì²˜ë¦¬
    - Null ê°’ì´ ì–¼ë§ˆë˜ì§€ ì•ŠëŠ” ê²½ìš° â†’ featureì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
    - Null ê°’ì´ ëŒ€ë¶€ë¶„ì¸ ê²½ìš° â†’ í•´ë‹¹ feature ë“œë¡­
    - Null ê°’ì´ ì• ë§¤í•˜ê²Œ ìˆëŠ” ê²½ìš° â†’ ë‹¨ìˆœíˆ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì—…ë¬´ ë¡œì§ë“±ì„ ìƒì„¸í•˜ê²Œ ê²€í† í•´ì•¼í•¨
- ë¬¸ìì—´ ì²˜ë¦¬
    - ì‚¬ì´í‚·ëŸ°ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ ë¬¸ìì—´ ê°’ì„ ì…ë ¥ê°’ìœ¼ë¡œ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
    - ë”°ë¼ì„œ ëª¨ë“  ë¬¸ìì—´ ê°’ì€ ì¸ì½”ë”©ë¼ì„œ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•´ì•¼í•œë‹¤. (ì£¼ë¯¼ë²ˆí˜¸ë‚˜ ë‹¨ìˆœ ë¬¸ìì—´ ì•„ì´ë”” ê°™ì€ ì˜ˆì¸¡ì— ë„ì›€ì´ ì•ˆë˜ëŠ” ë¶ˆí•„ìš”í•œ í”¼ì²˜ì¼ ê²½ìš°ëŠ” ê·¸ëƒ¥ ì‚­ì œ)

### 1) ë°ì´í„° ì¸ì½”ë”©

- **ë ˆì´ë¸” ì¸ì½”ë”© (Label encoding)**
    - ì¹´í…Œê³ ë¦¬ í”¼ì²˜ë¥¼ ì½”ë“œí˜• ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜
    - ì˜ˆ : ìƒí’ˆ ë°ì´í„°ì˜ ìƒí’ˆ êµ¬ë¶„ì´ TV, ëƒ‰ì¥ê³ , ì „ìë ˆì¸ì§€, ì»´í“¨í„°, ì„ í’ê¸°, ë¯¹ì„œë¡œ ë¼ ìˆë‹¤ë©´ 
    â†’ TV : 1, ëƒ‰ì¥ê³ : 2, ì „ìë ˆì¸ì§€: 3, ì»´í“¨í„°: 4, ì„ í’ê¸° :5, ë¯¹ì„œ : 6ê³¼ ê°™ì€ ìˆ«ìí˜• ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒ
    
    ```python
    from sklearn.preprocessing import LabelEncoder
    
    items=['TV','ëƒ‰ì¥ê³ ','ì „ìë Œì§€','ì»´í“¨í„°','ì„ í’ê¸°','ì„ í’ê¸°','ë¯¹ì„œ','ë¯¹ì„œ']
    
    # LabelEncoderë¥¼ ê°ì²´ë¡œ ìƒì„±í•œ í›„ , fit( ) ê³¼ transform( ) ìœ¼ë¡œ label ì¸ì½”ë”© ìˆ˜í–‰. 
    encoder = LabelEncoder()
    encoder.fit(items)
    labels = encoder.transform(items)
    print('ì¸ì½”ë”© ë³€í™˜ê°’:',labels)
    #  [0 1 4 5 3 3 2 2]
    ```
    
    ```python
    print('ì¸ì½”ë”© í´ë˜ìŠ¤:',encoder.classes_)  
    # ['TV' 'ëƒ‰ì¥ê³ ' 'ë¯¹ì„œ' 'ì„ í’ê¸°' 'ì „ìë Œì§€' 'ì»´í“¨í„°']
    
    print('ë””ì½”ë”© ì›ë³¸ ê°’:',encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))
    # ['ì „ìë Œì§€' 'ì»´í“¨í„°' 'ë¯¹ì„œ' 'TV' 'ëƒ‰ì¥ê³ ' 'ëƒ‰ì¥ê³ ' 'ì„ í’ê¸°' 'ì„ í’ê¸°']
    ```
    
    - ë‹¨ì  : ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜ë˜ë©´ì„œ íšŒê·€ê³„ì—´ì˜ ML ì•Œê³ ë¦¬ì¦˜ì— ì´ë¥¼ ì ìš©í•  ê²½ìš° ì˜ˆì¸¡ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê²Œ ë¨ â†’ ìˆ«ì ê°’ì˜ ê²½ìš° **í¬ê³  ì‘ìŒì— ëŒ€í•œ íŠ¹ì„±**ì´ ì‘ìš©í•˜ê¸° ë•Œë¬¸ â†’ ì›í•« ì¸ì½”ë”© ì ìš©

- **ì›-í•« ì¸ì½”ë”© (One-Hot encoding)**
    - í•´ë‹¹ ê³ ìœ  ê°’ì— ë§¤ì¹­ë˜ëŠ” í”¼ì²˜ë§Œ 1ì´ ë˜ê³  ë‚˜ë¨¸ì§€ í”¼ì²˜ëŠ” 0ì´ ë˜ê²Œë” ì¸ì½”ë”© í•˜ëŠ” ë°©ì‹
    - ì›-í•« ì¸ì½”ë”© ì¡°ê±´:
        
        1) ìš°ì„  ìˆ«ìí˜•íƒœì˜ ê°’ìœ¼ë¡œ ë³€í™˜ë˜ì–´ ìˆì–´ì•¼ í•¨
        2) 2ì°¨ì› ë°ì´í„°ë¡œ ë³€í™˜ë˜ì–´ ìˆì–´ì•¼ í•¨
        


```python
from sklearn.preprocessing import OneHotEncoder
import numpy as np

items=['TV','ëƒ‰ì¥ê³ ','ì „ìë Œì§€','ì»´í“¨í„°','ì„ í’ê¸°','ì„ í’ê¸°','ë¯¹ì„œ','ë¯¹ì„œ']

# ë¨¼ì € ìˆ«ìê°’ìœ¼ë¡œ ë³€í™˜ì„ ìœ„í•´ LabelEncoderë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
# 2ì°¨ì› ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
labels = labels.reshape(-1,1)

print('2ì°¨ì› ë°ì´í„°ë¡œ ë³€í™˜í›„')
print(labels)
--------------------------
[[0]
 [1]
 [4]
 [5]
 [3]
 [3]
 [2]
 [2]]

# ì›-í•« ì¸ì½”ë”©ì„ ì ìš©í•©ë‹ˆë‹¤. 
oh_encoder = OneHotEncoder()
oh_encoder.fit(labels)
oh_labels = oh_encoder.transform(labels)
print('ì›-í•« ì¸ì½”ë”© ë°ì´í„°')
print(oh_labels.toarray())
-----------------------------
[[1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0.]]

print('ì›-í•« ì¸ì½”ë”© ë°ì´í„° ì°¨ì›')
print(oh_labels.shape)   # (8, 6)
```

- Pandasë¡œ ì‰½ê²Œ ì›í•« ì¸ì½”ë”© ê°€ëŠ¥

```python
import pandas as pd

df = pd.DataFrame({'item':['TV','ëƒ‰ì¥ê³ ','ì „ìë Œì§€','ì»´í“¨í„°','ì„ í’ê¸°','ì„ í’ê¸°','ë¯¹ì„œ','ë¯¹ì„œ'] })
pd.get_dummies(df) #pandas ì—ì„œ ì œê³µí•˜ëŠ” ì›-í•« ì¸ì½”ë”© í•¨ìˆ˜(ì•„ì£¼ ê°„í¸í•¨)
```


### 2) í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ê³¼ ì •ê·œí™”

- ì„œë¡œ ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ê°’ ë²”ìœ„ë¥¼ ì¼ì •í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë§ì¶”ëŠ” ì‘ì—…ì„ feature scaling ì´ë¼ê³  í•œë‹¤.
- ëŒ€í‘œì ì¸ ë°©ë²•ìœ¼ë¡œ í‘œì¤€í™”(Standardization)ì™€ ì •ê·œí™”(Normalization)ì´ ìˆë‹¤.
- í‘œì¤€í™”
    - ë°ì´í„°ì˜ í”¼ì²˜ ê°ê°ì´ í‰ê· ì´ 0ì´ê³  ë¶„ì‚°ì´ 1ì¸ ê°€ìš°ì‹œê°„ ì •ê·œ ë¶„í¬ë¥¼ ê°€ì§„ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
    - í‘œì¤€í™”ë¥¼ í†µí•´ ë³€í™˜ë  í”¼ì²˜ xì˜ ìƒˆë¡œìš´ ië²ˆì§¸ ë°ì´í„° : xi_new
    - xi_new = (xi - mean(x))/stdev(x)
- ì •ê·œí™”
    - ì„œë¡œ ë‹¤ë¥¸ í”¼ì²˜ì˜ í¬ê¸°ë¥¼ í†µì¼í•˜ê¸° ìœ„í•´ í¬ê¸°ë¥¼ ë³€í™˜í•´ì£¼ëŠ ã„´ê°œë…
    - ì˜ˆ : í”¼ì²˜ AëŠ” ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ë¡œ ê°’ì´ 0 ~ 100KMë¡œ ì£¼ì–´ì§€ê³ , í”¼ì²˜ BëŠ” ê¸ˆì•¡ì„ ë‚˜íƒ€ë‚´ëŠ” ì†ì„±ìœ¼ë¡œ ê°’ì´ 0 ~ 100,000,000,000ì›ìœ¼ë¡œ ì£¼ì–´ì§„ë‹¤ë©´ ì´ ë³€ìˆ˜ë¥¼ ëª¨ë‘ ë™ì¼í•œ í¬ê¸° ë‹¨ìœ„ë¡œ ë¹„êµí•˜ê¸° ìœ„í•´ ê°’ì„ ëª¨ë‘ ìµœì†Œ 0~ ìµœëŒ€ 1ì˜ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒ.
    - ì¦‰, ê°œë³„ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ëª¨ë‘ ë˜‘ê°™ì€ ë‹¨ìœ„ë¡œ ë³€ê²½í•˜ëŠ” ê²ƒ

- **StandardScaler**
    - í‘œì¤€í™”ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤
    - ê°œë³„ í”¼ì²˜ë¥¼ í‰ê· ì´ 0ì´ê³  ë¶„ì‚°ì´ 1ì¸ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¥¼ ë”°ë¥´ë„ë¡ ë³€í™˜í•´ì¤Œ
    - RBF ì»¤ë„ì„ ì´ìš©í•˜ëŠ” ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ ì´ë‚˜ ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë°ì´í„°ê°€ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •í•˜ê³  êµ¬í˜„ëê¸° ë•Œë¬¸ì— í‘œì¤€í™”ë¥¼ ì ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.
    
    StandardScaler ì ìš© ì „
    
    ```python
    from sklearn.datasets import load_iris
    import pandas as pd
    # ë¶“ê½ƒ ë°ì´í„° ì…‹ì„ ë¡œë”©í•˜ê³  DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
    iris = load_iris()
    iris_data = iris.data
    iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
    
    print('feature ë“¤ì˜ í‰ê·  ê°’')
    print(iris_df.mean())
    print('\nfeature ë“¤ì˜ ë¶„ì‚° ê°’')
    print(iris_df.var())
    iris_df
    ```
    
    
    StandardScaler ì ìš© í›„
    
    ```python
    from sklearn.preprocessing import StandardScaler
    
    # StandardScalerê°ì²´ ìƒì„±
    scaler = StandardScaler()
    # StandardScaler ë¡œ ë°ì´í„° ì…‹ ë³€í™˜. fit( ) ê³¼ transform( ) í˜¸ì¶œ.  
    scaler.fit(iris_df)
    iris_scaled = scaler.transform(iris_df)
    
    #transform( )ì‹œ scale ë³€í™˜ëœ ë°ì´í„° ì…‹ì´ numpy ndarryë¡œ ë°˜í™˜ë˜ì–´ ì´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)
    print('feature ë“¤ì˜ í‰ê·  ê°’')
    print(iris_df_scaled.mean())
    print('\nfeature ë“¤ì˜ ë¶„ì‚° ê°’')
    print(iris_df_scaled.var())
    
    iris_df_scaled
    ```
    
    
    - ëª¨ë“  ì»¬ëŸ¼ ê°’ì˜ í‰ê· ì´ 0ì— ì•„ì£¼ ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ, ë¶„ì‚°ì€ 1ì— ì•„ì£¼ ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ ë³€í™˜ëìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.

- **MinMaxScaler**
    - ì •ê·œí™”ë¥¼ ì§€ì›í•˜ëŠ” í´ë˜ìŠ¤ì´ë©° 0ê³¼ 1ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì •ê·œí™” (ìŒìˆ˜ê°’ì˜ ê²½ìš° -1ê³¼ 1ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜)
    - ë°ì´í„°ì˜ ë¶„í¬ê°€ ì •ê·œë¶„í¬ê°€ ì•„ë‹ˆë¼ê³  íŒë‹¨ë˜ëŠ” ê²½ìš° ì‚¬ìš©ë¨
    
    ```python
    from sklearn.preprocessing import MinMaxScaler
    
    # MinMaxScalerê°ì²´ ìƒì„±
    scaler = MinMaxScaler()
    # MinMaxScaler ë¡œ ë°ì´í„° ì…‹ ë³€í™˜. fit() ê³¼ transform() í˜¸ì¶œ.  
    scaler.fit(iris_df)
    iris_scaled = scaler.transform(iris_df)
    
    # transform()ì‹œ scale ë³€í™˜ëœ ë°ì´í„° ì…‹ì´ numpy ndarryë¡œ ë°˜í™˜ë˜ì–´ ì´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)
    print('featureë“¤ì˜ ìµœì†Œ ê°’')
    print(iris_df_scaled.min())
    print('\nfeatureë“¤ì˜ ìµœëŒ€ ê°’')
    print(iris_df_scaled.max())
    ------------------------------------------
    featureë“¤ì˜ ìµœì†Œ ê°’
    sepal length (cm)    0.0
    sepal width (cm)     0.0
    petal length (cm)    0.0
    petal width (cm)     0.0
    dtype: float64
    
    featureë“¤ì˜ ìµœëŒ€ ê°’
    sepal length (cm)    1.0
    sepal width (cm)     1.0
    petal length (cm)    1.0
    petal width (cm)     1.0
    dtype: float64
    ```
    

- **Scalerë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— fit(), transform(), fit_transform() ì ìš© ì‹œ ìœ ì˜ì‚¬í•­**
    - Scaler ê°ì²´ë¥¼ ì´ìš©í•´ í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¡œ fit()ê³¼ transform()ì„ ì ìš©í•˜ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¡œëŠ” ë‹¤ì‹œ fit()ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ë°”ë¡œ transform()ì„ ìˆ˜í–‰í•´ì•¼í•¨
    - ì¦‰ í•™ìŠµ ë°ì´í„°ë¡œ fit()ì´ ì ìš©ëœ ìŠ¤ì¼€ì¼ë§ ê¸°ì¤€ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•´ì•¼í•œë‹¤.
    - ê·¸ë ‡ì§€ ì•Šê³  í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë‹¤ì‹œ ìƒˆë¡œìš´ ìŠ¤ì¼€ì¼ë§ ê¸°ì¤€ ì •ë³´ë¥¼ ë§Œë“¤ê²Œ ë˜ë©´ 
    â†’ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ ê¸°ì¤€ ì •ë³´ê°€ ì„œë¡œ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— 
    â†’ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ì§€ ëª»í•  ìˆ˜ ìˆë‹¤.

```python
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# í•™ìŠµ ë°ì´í„°ëŠ” 0 ë¶€í„° 10ê¹Œì§€, í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” 0 ë¶€í„° 5ê¹Œì§€ ê°’ì„ ê°€ì§€ëŠ” ë°ì´í„° ì„¸íŠ¸ë¡œ ìƒì„±
# Scalerí´ë˜ìŠ¤ì˜ fit(), transform()ì€ 2ì°¨ì› ì´ìƒ ë°ì´í„°ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ reshape(-1, 1)ë¡œ ì°¨ì› ë³€ê²½
train_array = np.arange(0, 11).reshape(-1, 1)
test_array =  np.arange(0, 6).reshape(-1, 1)
print('train_array')
print(train_array)
print('test_array')
print(test_array)
```

```python
# ìµœì†Œê°’ 0, ìµœëŒ€ê°’ 1ë¡œ ë³€í™˜í•˜ëŠ” MinMaxScalerê°ì²´ ìƒì„±
scaler = MinMaxScaler()
# fit()í•˜ê²Œ ë˜ë©´ train_array ë°ì´í„°ì˜ ìµœì†Œê°’ì´ 0, ìµœëŒ€ê°’ì´ 10ìœ¼ë¡œ ì„¤ì •.  
scaler.fit(train_array)
# 1/10 scaleë¡œ train_array ë°ì´í„° ë³€í™˜í•¨. ì›ë³¸ 10-> 1ë¡œ ë³€í™˜ë¨.
train_scaled = scaler.transform(train_array)
 
print('ì›ë³¸ train_array ë°ì´í„°:', np.round(train_array.reshape(-1), 2))
# [ 0  1  2  3  4  5  6  7  8  9 10]
print('Scaleëœ train_array ë°ì´í„°:', np.round(train_scaled.reshape(-1), 2))
# [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]
```

```python
# ì•ì—ì„œ ìƒì„±í•œ MinMaxScalerì— test_arrayë¥¼ fit()í•˜ê²Œ ë˜ë©´ ì›ë³¸ ë°ì´í„°ì˜ ìµœì†Œê°’ì´ 0, ìµœëŒ€ê°’ì´ 5ìœ¼ë¡œ ì„¤ì •ë¨ 
scaler.fit(test_array)
# 1/5 scaleë¡œ test_array ë°ì´í„° ë³€í™˜í•¨. ì›ë³¸ 5->1ë¡œ ë³€í™˜.  
test_scaled = scaler.transform(test_array)
# train_array ë³€í™˜ ì¶œë ¥
print('ì›ë³¸ test_array ë°ì´í„°:', np.round(test_array.reshape(-1), 2))
# [0 1 2 3 4 5]
print('Scaleëœ test_array ë°ì´í„°:', np.round(test_scaled.reshape(-1), 2))
# [0.  0.2 0.4 0.6 0.8 1. ]
```

```python
scaler = MinMaxScaler()
scaler.fit(train_array)
train_scaled = scaler.transform(train_array)
print('ì›ë³¸ train_array ë°ì´í„°:', np.round(train_array.reshape(-1), 2))
# [ 0  1  2  3  4  5  6  7  8  9 10]
print('Scaleëœ train_array ë°ì´í„°:', np.round(train_scaled.reshape(-1), 2))
# [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]

# test_arrayì— Scale ë³€í™˜ì„ í•  ë•ŒëŠ” ë°˜ë“œì‹œ fit()ì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ì§€ ì•Šê³  trainì— ì‚¬ìš©ë˜ì—ˆë˜ ìŠ¤ì¼€ì¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ì„œ transform() ë§Œìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨. 
test_scaled = scaler.transform(test_array)
print('\nì›ë³¸ test_array ë°ì´í„°:', np.round(test_array.reshape(-1), 2))
# [0 1 2 3 4 5]
print('Scaleëœ test_array ë°ì´í„°:', np.round(test_scaled.reshape(-1), 2))
# [0.  0.1 0.2 0.3 0.4 0.5]
```
